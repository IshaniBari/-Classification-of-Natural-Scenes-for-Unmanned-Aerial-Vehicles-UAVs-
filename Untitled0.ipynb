{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqsndMKoHzxzX4HcTSEUM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaniBari/Classification-of-Natural-Scenes-for-Unmanned-Aerial-Vehicles-UAVs/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX5qU5ynle5h"
      },
      "source": [
        "<h3 align='center'><b>PROJECT TITLE - Classification of Natural Scenes for an Unmanned Aerial Vehicles (UAVs)</b></h3>\n",
        "\n",
        "**Team Name - 4 Folds**\n",
        "\n",
        "**Team Members** -<br>\n",
        "*   Heera Lal\n",
        "*   Ishani Bari\n",
        "*   Muhammad Akmal \n",
        "*   Umang Agarwal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s-8NE8Ine50"
      },
      "source": [
        "**PROBLEM STATEMENT** - <br>\n",
        "To predict the natural scenes around the flying object to tune the unmanned aerial systems.\n",
        "\n",
        "**DESCRIPTION** - <BR>\n",
        "Unmanned Aerial Vehicles requires the information about the surrounding scene to operate in its optimal conditions. We are trying to build a model to classify natural scenes that the object might encounter. -<br>\n",
        "\n",
        "**DATASET** -<br>\n",
        "This Data contains around 14k training images, 3k images for test and some images for prediction of size 150x150 distributed under 6 categories.<br>\n",
        "Buildings : 0<br>\n",
        "Forest    : 1<br>\n",
        "Glacier   : 2<br>\n",
        "Mountain  : 3<br>\n",
        "Sea       : 4<br>\n",
        "Street    : 5 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu82Pt1WqdBC"
      },
      "source": [
        "**OUR APPROACH TO THIS PROBLEM STATEMENT**-<br>\n",
        "We tried 2 approches for this considering that we are building a model for UAV's to classify natural scenes -<br>\n",
        "<U>**APPROACH 1**</U> -<br>\n",
        "* Read the data from train and test directories as array into size of **64X64** (so as to reduce the training time and induce some noise in image) into X_train,y_train, X_test and y_test where X_train and X_test would contain images and y_train and y_test would contain corresponding labels. \n",
        "* Took **200 images from each class** and merged these images so total of **1200 images** and performed **5 Data Augmentation** (rotation, zoom, brightness, shear and night vision) on these 1200 images (like each of these 5 augmentations on 1200 images). After augmentation, we have 6000 augmented images **(1200 X 5)**, so we concatenated these 6000 images to X_train. Now, the X_train has **14k+6k** images for **training**.\n",
        "* **CNN Model Architectures** - Tried 3 different model architectures.\n",
        "* Model Evaluation and model selection.\n",
        "* Visualization **(Saliency Maps and GradCAM)**\n",
        "* Took 2 images from prediction data and tried predicting its class.\n",
        "\n",
        "\n",
        "<U>**APPROACH 2**</U> -<br>\n",
        "* Defined different functions for performing different augmentations - **(rotation, zoom, brightness, shear and night vision)**.\n",
        "* Defined a funtion to **perfrom 2 to 5 augmentations randomly** on the each image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_HJRCN_uApP"
      },
      "source": [
        "#### **Importing the Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewPicllX5QBf"
      },
      "outputs": [],
      "source": [
        "!pip3 -qq install tf_keras_vis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFEoeyieXGpZ"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "import random\n",
        "random.seed(112358)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "\n",
        "from IPython.display import Image\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score , classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils import normalize\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "import visualkeras\n",
        "\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD , Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, InputLayer, ReLU , BatchNormalization\n",
        "\n",
        "%matplotlib inline\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDZfiRYGLMuV",
        "outputId": "560f9f6f-a47f-4d3a-d6b8-c4e09924e708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Classes:  6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keys</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>buildings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>glacier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mountain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>street</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Keys     Labels\n",
              "0     0  buildings\n",
              "1     1     forest\n",
              "2     2    glacier\n",
              "3     3   mountain\n",
              "4     4        sea\n",
              "5     5     street"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating dictionary to turn different scenes index into class labels\n",
        "scenedict = {\n",
        "     0 : 'buildings',\n",
        "     1 : 'forest',\n",
        "     2 : 'glacier',\n",
        "     3 : 'mountain',\n",
        "     4 : 'sea',\n",
        "     5 : 'street',\n",
        "}\n",
        "n_classes = len(scenedict.keys())\n",
        "\n",
        "print('Total Classes: ',n_classes)\n",
        "pd.DataFrame({\"Keys\" : scenedict.keys(),\n",
        "              \"Labels\" : scenedict.values()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcpczwRUNwlq"
      },
      "source": [
        "<h2><U><b>APPROACH 1</b></U> </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuLs2AYlMRAc"
      },
      "source": [
        "#### 1. Loading Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWoakQMsMIhL"
      },
      "outputs": [],
      "source": [
        "# Defining a function get_data (images) from a given data directory \n",
        "# resize it to target size i.e. (64,64) and store the images in labels separately\n",
        "def get_data(data_dir):\n",
        "    train_img = []\n",
        "    train_label = [] \n",
        "    for label in os.listdir(data_dir):\n",
        "        lab = label\n",
        "        for img_id in os.listdir('/'.join([data_dir, label])):\n",
        "            img = load_img('/'.join([data_dir, label, img_id]), target_size=(64,64))\n",
        "            img = img_to_array(img)\n",
        "            train_img.append(img)\n",
        "            train_label.append(lab)\n",
        "    return train_img , train_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh5e-64kM3jI"
      },
      "outputs": [],
      "source": [
        "# Getting the train_data in train_dir\n",
        "train_data_path = r'C:\\Users\\UMANG\\AI-2\\Project\\OG_Data'\n",
        "train_dir = os.path.join(train_data_path,'seg_train')\n",
        "\n",
        "# Getting the test_data in test_dir\n",
        "test_dir = os.path.join(train_data_path,'seg_test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O42p5be1OCOJ"
      },
      "source": [
        "Loading the train data as images and labels using the get_data function defined above"
      ]
    }
  ]
}